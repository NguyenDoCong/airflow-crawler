[2025-05-08T02:51:20.256+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-05-08T02:51:20.268+0000] {taskinstance.py:2603} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: facebook_videos_scraper_dag.fb_videos_scraper manual__2025-05-08T02:51:12.561802+00:00 [queued]>
[2025-05-08T02:51:20.272+0000] {taskinstance.py:2603} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: facebook_videos_scraper_dag.fb_videos_scraper manual__2025-05-08T02:51:12.561802+00:00 [queued]>
[2025-05-08T02:51:20.273+0000] {taskinstance.py:2856} INFO - Starting attempt 1 of 1
[2025-05-08T02:51:20.281+0000] {taskinstance.py:2879} INFO - Executing <Task(_PythonDecoratedOperator): fb_videos_scraper> on 2025-05-08 02:51:12.561802+00:00
[2025-05-08T02:51:20.283+0000] {standard_task_runner.py:72} INFO - Started process 1582 to run task
[2025-05-08T02:51:20.286+0000] {standard_task_runner.py:104} INFO - Running: ['airflow', 'tasks', 'run', 'facebook_videos_scraper_dag', 'fb_videos_scraper', 'manual__2025-05-08T02:51:12.561802+00:00', '--job-id', '4920', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmppw8458nw']
[2025-05-08T02:51:20.287+0000] {standard_task_runner.py:105} INFO - Job 4920: Subtask fb_videos_scraper
[2025-05-08T02:51:20.320+0000] {task_command.py:467} INFO - Running <TaskInstance: facebook_videos_scraper_dag.fb_videos_scraper manual__2025-05-08T02:51:12.561802+00:00 [running]> on host 83f5c4ce7f9b
[2025-05-08T02:51:20.369+0000] {taskinstance.py:3122} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='facebook_videos_scraper_dag' AIRFLOW_CTX_TASK_ID='fb_videos_scraper' AIRFLOW_CTX_EXECUTION_DATE='2025-05-08T02:51:12.561802+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-05-08T02:51:12.561802+00:00'
[2025-05-08T02:51:20.370+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-05-08T02:51:20.394+0000] {selenium_manager.py:133} WARNING - The chromedriver version (136.0.7103.59) detected in PATH at /usr/bin/chromedriver might not be compatible with the detected chrome version (136.0.7103.92); currently, chromedriver 136.0.7103.92 is recommended for chrome 136.*, so it is advised to delete the driver in PATH and retry
[2025-05-08T03:00:35.144+0000] {logging_mixin.py:190} INFO - Step 1 of 3 - Load cookies
[2025-05-08T03:00:38.896+0000] {logging_mixin.py:190} INFO - An Error occurred while loading cookies Message: tab crashed
  (Session info: chrome=136.0.7103.92)
Stacktrace:
#0 0x561223c3da8e <unknown>
#1 0x5612236fa7f6 <unknown>
#2 0x5612236e761f <unknown>
#3 0x5612236e6a3d <unknown>
#4 0x5612236e617b <unknown>
#5 0x5612236e60bc <unknown>
#6 0x5612236e4608 <unknown>
#7 0x5612236e4ab9 <unknown>
#8 0x5612236f2160 <unknown>
#9 0x5612237084ff <unknown>
#10 0x56122370da4b <unknown>
#11 0x5612236e502d <unknown>
#12 0x561223707f5d <unknown>
#13 0x56122379002c <unknown>
#14 0x56122376e9b3 <unknown>
#15 0x561223738c59 <unknown>
#16 0x561223739a08 <unknown>
#17 0x561223c0a40a <unknown>
#18 0x561223c0d85e <unknown>
#19 0x561223c0d308 <unknown>
#20 0x561223c0dce5 <unknown>
#21 0x561223bf3b7b <unknown>
#22 0x561223c0e050 <unknown>
#23 0x561223bdcae9 <unknown>
#24 0x561223c2cdf5 <unknown>
#25 0x561223c2cfdb <unknown>
#26 0x561223c3cc05 <unknown>
#27 0x7fd261f7b134 <unknown>
[2025-05-08T03:00:38.902+0000] {logging_mixin.py:190} INFO - An error occurred Message: tab crashed
  (Session info: chrome=136.0.7103.92)
Stacktrace:
#0 0x561223c3da8e <unknown>
#1 0x5612236fa7f6 <unknown>
#2 0x5612236e6073 <unknown>
#3 0x5612236e4608 <unknown>
#4 0x5612236e4ab9 <unknown>
#5 0x5612236f2160 <unknown>
#6 0x5612237084ff <unknown>
#7 0x56122370da4b <unknown>
#8 0x5612236e502d <unknown>
#9 0x561223707f5d <unknown>
#10 0x56122378fcf7 <unknown>
#11 0x56122376e9b3 <unknown>
#12 0x561223738c59 <unknown>
#13 0x561223739a08 <unknown>
#14 0x561223c0a40a <unknown>
#15 0x561223c0d85e <unknown>
#16 0x561223c0d308 <unknown>
#17 0x561223c0dce5 <unknown>
#18 0x561223bf3b7b <unknown>
#19 0x561223c0e050 <unknown>
#20 0x561223bdcae9 <unknown>
#21 0x561223c2cdf5 <unknown>
#22 0x561223c2cfdb <unknown>
#23 0x561223c3cc05 <unknown>
#24 0x7fd261f7b134 <unknown>
[2025-05-08T03:00:38.902+0000] {logging_mixin.py:190} INFO - Reading URLs from scraped_data/facebook.txt...
[2025-05-08T03:00:39.570+0000] {taskinstance.py:3301} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 406, in wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/decorators/base.py", line 266, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 406, in wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/operators/python.py", line 238, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/operators/python.py", line 256, in execute_callable
    return runner.run(*self.op_args, **self.op_kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
  File "/opt/airflow/dags/tasks/fb_videos_scraper.py", line 13, in fb_videos_scraper
    batch_download_from_file(FACEBOOK_FILE_PATH, DOWNLOAD_DIRECTORY, tiktok=False)
  File "/opt/airflow/dags/utils/downloader.py", line 115, in batch_download_from_file
    with open(file_path, "r") as file:
IsADirectoryError: [Errno 21] Is a directory: 'scraped_data/facebook.txt'
[2025-05-08T03:00:39.580+0000] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=facebook_videos_scraper_dag, task_id=fb_videos_scraper, run_id=manual__2025-05-08T02:51:12.561802+00:00, execution_date=20250508T025112, start_date=20250508T025120, end_date=20250508T030039
[2025-05-08T03:00:39.593+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-05-08T03:00:39.593+0000] {standard_task_runner.py:124} ERROR - Failed to execute job 4920 for task fb_videos_scraper ([Errno 21] Is a directory: 'scraped_data/facebook.txt'; 1582)
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/task/task_runner/standard_task_runner.py", line 117, in _start_by_fork
    ret = args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 115, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/task_command.py", line 483, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/task_command.py", line 256, in _run_task_by_selected_method
    return _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/task_command.py", line 341, in _run_raw_task
    return ti._run_raw_task(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 2995, in _run_raw_task
    return _run_raw_task(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 3149, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 3173, in _execute_task
    return _execute_task(self, context, task_orig)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 406, in wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/decorators/base.py", line 266, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 406, in wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/operators/python.py", line 238, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/operators/python.py", line 256, in execute_callable
    return runner.run(*self.op_args, **self.op_kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
  File "/opt/airflow/dags/tasks/fb_videos_scraper.py", line 13, in fb_videos_scraper
    batch_download_from_file(FACEBOOK_FILE_PATH, DOWNLOAD_DIRECTORY, tiktok=False)
  File "/opt/airflow/dags/utils/downloader.py", line 115, in batch_download_from_file
    with open(file_path, "r") as file:
IsADirectoryError: [Errno 21] Is a directory: 'scraped_data/facebook.txt'
[2025-05-08T03:00:39.624+0000] {local_task_job_runner.py:261} INFO - Task exited with return code 1
[2025-05-08T03:00:39.637+0000] {taskinstance.py:3891} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-05-08T03:00:39.638+0000] {local_task_job_runner.py:240} INFO - ::endgroup::
